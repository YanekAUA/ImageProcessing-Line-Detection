# Text Line Recognition Project
<!-- 
The Project aims at detection / recognition of stone inscriptions. Due to weathering, vandalism,
erosion, and the complexity of ancient scripts, many of these texts are hard to read. Study, apply
and test Image Processing methods and algorithms to detect Armenian inscriptions.
The shapes of Armenian letters are based on vertical strokes. Based on this observation, implement
and test a pipeline outlined below. Implement the steps as ImageJ plug-ins or menu commands,
and save them using the ImageJ macro recorder. In addition to the recorded macro(s), submit the
code of all implemented plug-ins. Other image processing and programming environments may
be used only for testing purposes. -->

The Project aims at detection / recognition of stone inscriptions. Due to weathering, vandalism, erosion, and the complexity of ancient scripts, many of these texts are hard to read. Study, apply and test Image Processing methods and algorithms to detect Armenian inscriptions. The shapes of Armenian letters are based on vertical strokes. Based on this observation, implement and test a pipeline outlined below. Implement the steps as ImageJ plug-ins or menu commands, and save them using the ImageJ macro recorder. In addition to the recorded macro(s), submit the code of all implemented plug-ins. Other image processing and programming environments may be used only for testing purposes.

# Part 1: Text Line Detection
## STEPS:
### Description Submission

|  Step  | Description                                                                                                                                                                                                                                                                                                                           | Submission                                                                      |                                               Current Status                                                |
| :----: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------------------------: |
| **0**  | Create a Google Drive and share its link/send invitation to **skhachat@aua.am** and **eduard_grigoryan@edu.aua.am**. Make sure your name is explicitly reflected in the title. All project deliverables will be collected in its **Lines** subfolder.                                                                                 |                                                                                 |                                                      ✅                                                      |
| **1**  | Select several images of **tombstones (tapanakars), cross-stones (khachkars), or monuments with Armenian inscriptions**. Make them **grayscale** and process as outlined below.                                                                                                                                                       | The image files and source links.                                               |                                        ✅ [path to images](./images)                                         |
| **2**  | **Detect the vertical edges** (both east and west edges) using **Edge Detection Operators** (Chapter 6). Make the images of the detected edges **binary**. **Combine** the detected east and west edges in a binary image.                                                                                                            | Kernels of the edge operators and the images of east, west, and combined edges. |                     ✅ Kernels and edge operators are in the macro `vertical-edges.java`                     |
| **3**  | **Strengthen the detected vertical edges** by applying **1 pixel-wide dilation in horizontal direction** and **1 pixel-wide erosion in vertical direction** (Chapter 9).                                                                                                                                                              | Structuring elements and the images after dilation and erosion.                 | ✅ Implemented using convolution kernels (horizontal dilation and vertical erosion) in `vertical-edges.java` |
| **4**  | **Denoise** the image of the strengthened vertical edges by applying **linear and/or nonlinear filters of unit radius** (Chapter 5). Make sure the image stays **binary** after denoising.                                                                                                                                            | The filter(s) and kernel(s), and the denoised image of vertical edges.          |                        ✅ Implemented (median filter applied; result saved in `.tmp`)                        |
| **5**  | To detect text regions (which have a high-frequency structure), apply the **Bandpass Filter**. Try different values for **large structures** and **small structures limits** (e.g., 40 and 30 pixels) to produce horizontally aligned regions that resemble words or entire text lines (Chapter 19).                                  | The filtered image.                                                             |               ✅ Implemented via Bandpass Filter and saved as `vertical-edges-bandpassed.tif`                |
| **6**  | If necessary, use the filtered image from step 5 as a **binary mask** for the denoised image of the vertical edges from step 4 by applying the **AND operation**.                                                                                                                                                                     | The masked image.                                                               |                         ✅ Implemented; result saved as `vertical-edges-masked.tif`                          |
| **7**  | If step 6 was implemented, apply the same **Bandpass Filter** from step 5 to the masked image.                                                                                                                                                                                                                                        | The filtered masked image.                                                      |                       ✅ Implemented; saved as `vertical-edges-masked-bandpassed.tif`                        |
| **8**  | **Analyze the particles** in the filtered image from step 5 or step 7 and show the **fitting ellipses** (Chapter 10).                                                                                                                                                                                                                 | The image with fitting ellipses of the analyzed particles.                      |   ✅ Implemented using `Analyze Particles` with `show=Ellipses` and saved as `vertical-edges-ellipses.tif`   |
| **9**  | **Skeletonize** the filtered image from step 5 or step 7 or the fitting ellipses from step 8 (Chapter 9).                                                                                                                                                                                                                             | The images after the skeletonization.                                           |                 ✅ Implemented (skeletonize on `vertical-edges-ellipses.tif`; result saved)                  |
| **10** | **Detect the horizontal lines** by applying **Hough Transform** (Chapter 7). Use **Hough\_Transform.java PlugInFilter**. The horizontal lines are identified by the angle $\pi/2$. Convert the image of the Hough Transform to grayscale and apply a **threshold** to its region around angle $\pi/2$ to locate the horizontal lines. | The result of the Hough Transform.                                              |                                                   ✅ Done                                                    |
| **11** | **Write a plugin** that locates on the **original image** the horizontal lines detected by the Hough Transform. Check if these lines represent the text lines.                                                                                                                                                                        | The plugin and the image with the located text lines.                           |                                                   ✅ Done                                                    |
| **12** | Compute the **horizontal projection** of the binary image from step 4 and locate the **minimum points** around the horizontal lines detected in step 11.                                                                                                                                                                              | Image with the top and bottom boundaries of the detected text lines.            |                                                   ✅ Done                                                    |


# Part 2: Character Detection
## STEPS:
### Project 2 Implementation Steps

| #      | Description                                                                                                                                                                                                                                                                                                    | Submission                                                                                                          | Status                                                                 |
| ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| **0**  | Create in the shared Google drive a subfolder `\Lines2`. If needed, revisit Project 1 collect the revisited deliverables in this subfolder. The original subfolder `\Lines2` must not be changed.                                                                                                              |                                                                                                                     | ✅                                                                      |
| **1**  | Use the same images as in Project 1. Crop the text lines manually or, ideally, based on the results of Project 1. Apply the subsequent steps to different cropped text line images.                                                                                                                            | The cropped image files of individual text lines together with the coordinates and dimensions of the cropping boxes | ✅                                                                      |
| **2**  | Enhance the contrast of the carved symbols in the text line by trying different combinations of Image → Adjust → Brightness/Contrast... → Auto, Process → Sharpen, Process Filters → Gaussian Blur... (radius 1.00), Cut_After_Max command (the last Quiz). Find Cut_After_Max.java plugin uploaded in Moodle. | Histogram of the original cropped images and histograms after each applied command                                  | ✅                                                                      |
| **3**  | Apply Fourier Transform to the cropped image of enhanced contrast from step 2.                                                                                                                                                                                                                                 | The image of the FFT result                                                                                         | ✅                                                                      |
| **4**  | Enhance the contrast of the FFT result from step 3 using the same Image → Adjust → Brightness/Contrast... → Auto command.                                                                                                                                                                                      | The image of the enhanced FFT result                                                                                | ✅                                                                      |
| **5**  | Extract the brightest pixels from the enhanced FFT image from step 4 by running Image → Adjust → Threshold... command.                                                                                                                                                                                         | The filtered binarized FFT image                                                                                    | ✅                                                                      |
| **6**  | In the binarized FFT image from step 5 detect average periods between the strokes and / or symbols manually or, ideally, using Analyze Particles... command. Preprocess the FFT image as needed.                                                                                                               | The detected period(s)                                                                                              | ✅                                                                      |
| **7**  | Identify the most prominent stroke in the enhanced cropped image from step 2. For example, compute the vertical projection and locate the maximum point.                                                                                                                                                       | The x coordinate of the most prominent stroke                                                                       | ✅                                                                      |
| **8**  | Binarize the image of the text line and draw boxes of equal width detected in step 6 both sides from the stroke detected in step 7.                                                                                                                                                                            | The image of the binarized text line with the drawn boxes                                                           | ✅The boxes are not that good (maybe only the prominent is not enough)  |
| **9**  | Select a binary image of the Armenian alphabet, skeletonize it and compute Hu's invariant moments for each letter (chapter 10, section 10.6.4).                                                                                                                                                                | The skeletonized image and the 7-component vector of Hu's invariant moments for each letter                         | ✅Have the letter crops, skeletonization and feature calculation script |
| **10** | Compute Hu's invariant moments of binary regions in individual and / or two or more adjacent cells from step 8.                                                                                                                                                                                                | 7-component vector of Hu's invariant moments for each computed cell                                                 | ⌛                                                                      |
| **11** | Use the results of step 9 and step 10 to estimate / classify a symbol in each cell.                                                                                                                                                                                                                            | Classification of the symbols                                                                                       | ⌛                                                                      |
| **12** | Implement (fully or partially) the steps 1-8 as a macro and construct a table to indicate which step succeeded and which one failed for each processed text line.                                                                                                                                              | The constructed table electronically and in hard copy                                                               |                                                                        |
